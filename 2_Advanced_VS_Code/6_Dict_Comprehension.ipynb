{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   job_title_short        785741 non-null  object        \n",
      " 1   job_title              785740 non-null  object        \n",
      " 2   job_location           784696 non-null  object        \n",
      " 3   job_via                785733 non-null  object        \n",
      " 4   job_schedule_type      773074 non-null  object        \n",
      " 5   job_work_from_home     785741 non-null  bool          \n",
      " 6   search_location        785741 non-null  object        \n",
      " 7   job_posted_date        785741 non-null  datetime64[ns]\n",
      " 8   job_no_degree_mention  785741 non-null  bool          \n",
      " 9   job_health_insurance   785741 non-null  bool          \n",
      " 10  job_country            785692 non-null  object        \n",
      " 11  salary_rate            33067 non-null   object        \n",
      " 12  salary_year_avg        22003 non-null   float64       \n",
      " 13  salary_hour_avg        10662 non-null   float64       \n",
      " 14  company_name           785723 non-null  object        \n",
      " 15  job_skills             668704 non-null  object        \n",
      " 16  job_type_skills        668704 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"lukebarousse/data_jobs\")\n",
    "df = data[\"train\"].to_pandas()\n",
    "\n",
    "df[\"job_posted_date\"] = pd.to_datetime(df.job_posted_date)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Say I want dataframes representing the data of individual months \n",
    "# One way to manually create each dfs using condition but its so tidious work\n",
    "# We want to automate that.\n",
    "# So What IF we create a dictionary where each key representing the month and its associate value contain data for that month\n",
    "# Thats where we use dictionary comprehension similar to list comprehension, where we use for loop to atomate the process.\n",
    "\n",
    "# Okay first for defining keys we neeed a array of months name So lets create it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "      <th>job_posted_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee MÃ©xico</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "      <td>Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>via Diversity.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-07-04 13:01:41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest Research Institute</td>\n",
       "      <td>['python', 'c++', 'java', 'matlab', 'aws', 'te...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['tensorflow',...</td>\n",
       "      <td>Jul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer- Sr Jobs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-08-07 14:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kristina Daniel</td>\n",
       "      <td>['bash', 'python', 'oracle', 'aws', 'ansible',...</td>\n",
       "      <td>{'cloud': ['oracle', 'aws'], 'other': ['ansibl...</td>\n",
       "      <td>Aug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job_title_short  ... job_posted_month\n",
       "0  Senior Data Engineer  ...              Jun\n",
       "1          Data Analyst  ...              Jan\n",
       "2         Data Engineer  ...              Oct\n",
       "3         Data Engineer  ...              Jul\n",
       "4         Data Engineer  ...              Aug\n",
       "\n",
       "[5 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"job_posted_month\"] = df.job_posted_date.dt.strftime(\"%b\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_arr = df.job_posted_month.unique()\n",
    "\n",
    "month_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay now we are ready to do dictionary comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jun':                   job_title_short  ... job_posted_month\n",
       " 0            Senior Data Engineer  ...              Jun\n",
       " 8                Business Analyst  ...              Jun\n",
       " 16                  Data Engineer  ...              Jun\n",
       " 17                 Data Scientist  ...              Jun\n",
       " 24                 Data Scientist  ...              Jun\n",
       " ...                           ...  ...              ...\n",
       " 785347             Data Scientist  ...              Jun\n",
       " 785571               Data Analyst  ...              Jun\n",
       " 785617               Data Analyst  ...              Jun\n",
       " 785669  Machine Learning Engineer  ...              Jun\n",
       " 785675               Data Analyst  ...              Jun\n",
       " \n",
       " [61572 rows x 18 columns],\n",
       " 'Jan':           job_title_short  ... job_posted_month\n",
       " 1            Data Analyst  ...              Jan\n",
       " 20         Data Scientist  ...              Jan\n",
       " 39          Data Engineer  ...              Jan\n",
       " 53          Data Engineer  ...              Jan\n",
       " 55         Data Scientist  ...              Jan\n",
       " ...                   ...  ...              ...\n",
       " 785699  Software Engineer  ...              Jan\n",
       " 785700      Data Engineer  ...              Jan\n",
       " 785703       Data Analyst  ...              Jan\n",
       " 785704   Business Analyst  ...              Jan\n",
       " 785705       Data Analyst  ...              Jan\n",
       " \n",
       " [91822 rows x 18 columns],\n",
       " 'Oct':               job_title_short  ... job_posted_month\n",
       " 2               Data Engineer  ...              Oct\n",
       " 15              Data Engineer  ...              Oct\n",
       " 18               Data Analyst  ...              Oct\n",
       " 31               Data Analyst  ...              Oct\n",
       " 46               Data Analyst  ...              Oct\n",
       " ...                       ...  ...              ...\n",
       " 785670      Software Engineer  ...              Oct\n",
       " 785671  Senior Data Scientist  ...              Oct\n",
       " 785673         Data Scientist  ...              Oct\n",
       " 785681          Data Engineer  ...              Oct\n",
       " 785696  Senior Data Scientist  ...              Oct\n",
       " \n",
       " [66611 rows x 18 columns],\n",
       " 'Jul':        job_title_short  ... job_posted_month\n",
       " 3        Data Engineer  ...              Jul\n",
       " 14       Data Engineer  ...              Jul\n",
       " 37       Data Engineer  ...              Jul\n",
       " 38        Data Analyst  ...              Jul\n",
       " 95       Data Engineer  ...              Jul\n",
       " ...                ...  ...              ...\n",
       " 785465   Data Engineer  ...              Jul\n",
       " 785509    Data Analyst  ...              Jul\n",
       " 785540  Data Scientist  ...              Jul\n",
       " 785610    Data Analyst  ...              Jul\n",
       " 785685    Data Analyst  ...              Jul\n",
       " \n",
       " [63777 rows x 18 columns],\n",
       " 'Aug':                   job_title_short  ... job_posted_month\n",
       " 4                   Data Engineer  ...              Aug\n",
       " 28                 Data Scientist  ...              Aug\n",
       " 50      Machine Learning Engineer  ...              Aug\n",
       " 57                  Data Engineer  ...              Aug\n",
       " 59                  Data Engineer  ...              Aug\n",
       " ...                           ...  ...              ...\n",
       " 785661          Software Engineer  ...              Aug\n",
       " 785668               Data Analyst  ...              Aug\n",
       " 785672             Cloud Engineer  ...              Aug\n",
       " 785698              Data Engineer  ...              Aug\n",
       " 785701              Data Engineer  ...              Aug\n",
       " \n",
       " [75162 rows x 18 columns],\n",
       " 'Nov':              job_title_short  ... job_posted_month\n",
       " 5              Data Engineer  ...              Nov\n",
       " 11             Data Engineer  ...              Nov\n",
       " 13      Senior Data Engineer  ...              Nov\n",
       " 36              Data Analyst  ...              Nov\n",
       " 41            Data Scientist  ...              Nov\n",
       " ...                      ...  ...              ...\n",
       " 785576         Data Engineer  ...              Nov\n",
       " 785593      Business Analyst  ...              Nov\n",
       " 785643        Data Scientist  ...              Nov\n",
       " 785686      Business Analyst  ...              Nov\n",
       " 785706         Data Engineer  ...              Nov\n",
       " \n",
       " [64450 rows x 18 columns],\n",
       " 'Mar':              job_title_short  ... job_posted_month\n",
       " 6       Senior Data Engineer  ...              Mar\n",
       " 29            Data Scientist  ...              Mar\n",
       " 30      Senior Data Engineer  ...              Mar\n",
       " 32            Data Scientist  ...              Mar\n",
       " 66          Business Analyst  ...              Mar\n",
       " ...                      ...  ...              ...\n",
       " 785736     Software Engineer  ...              Mar\n",
       " 785737          Data Analyst  ...              Mar\n",
       " 785738      Business Analyst  ...              Mar\n",
       " 785739         Data Engineer  ...              Mar\n",
       " 785740     Software Engineer  ...              Mar\n",
       " \n",
       " [64084 rows x 18 columns],\n",
       " 'Dec':              job_title_short  ... job_posted_month\n",
       " 7              Data Engineer  ...              Dec\n",
       " 12              Data Analyst  ...              Dec\n",
       " 82             Data Engineer  ...              Dec\n",
       " 86             Data Engineer  ...              Dec\n",
       " 89      Senior Data Engineer  ...              Dec\n",
       " ...                      ...  ...              ...\n",
       " 785609         Data Engineer  ...              Dec\n",
       " 785623         Data Engineer  ...              Dec\n",
       " 785640          Data Analyst  ...              Dec\n",
       " 785662      Business Analyst  ...              Dec\n",
       " 785677        Cloud Engineer  ...              Dec\n",
       " \n",
       " [56303 rows x 18 columns],\n",
       " 'Apr':           job_title_short  ... job_posted_month\n",
       " 9          Data Scientist  ...              Apr\n",
       " 10          Data Engineer  ...              Apr\n",
       " 19         Data Scientist  ...              Apr\n",
       " 40         Data Scientist  ...              Apr\n",
       " 44         Data Scientist  ...              Apr\n",
       " ...                   ...  ...              ...\n",
       " 785619  Software Engineer  ...              Apr\n",
       " 785648     Data Scientist  ...              Apr\n",
       " 785650  Software Engineer  ...              Apr\n",
       " 785692     Data Scientist  ...              Apr\n",
       " 785702   Business Analyst  ...              Apr\n",
       " \n",
       " [62919 rows x 18 columns],\n",
       " 'Feb':              job_title_short  ... job_posted_month\n",
       " 21            Data Scientist  ...              Feb\n",
       " 27             Data Engineer  ...              Feb\n",
       " 34              Data Analyst  ...              Feb\n",
       " 35             Data Engineer  ...              Feb\n",
       " 62            Data Scientist  ...              Feb\n",
       " ...                      ...  ...              ...\n",
       " 784588         Data Engineer  ...              Feb\n",
       " 784779  Senior Data Engineer  ...              Feb\n",
       " 784994     Software Engineer  ...              Feb\n",
       " 785142      Business Analyst  ...              Feb\n",
       " 785402     Software Engineer  ...              Feb\n",
       " \n",
       " [64578 rows x 18 columns],\n",
       " 'Sep':                   job_title_short  ... job_posted_month\n",
       " 22                  Data Engineer  ...              Sep\n",
       " 23      Machine Learning Engineer  ...              Sep\n",
       " 26                  Data Engineer  ...              Sep\n",
       " 43           Senior Data Engineer  ...              Sep\n",
       " 49          Senior Data Scientist  ...              Sep\n",
       " ...                           ...  ...              ...\n",
       " 785618               Data Analyst  ...              Sep\n",
       " 785621              Data Engineer  ...              Sep\n",
       " 785629             Cloud Engineer  ...              Sep\n",
       " 785657               Data Analyst  ...              Sep\n",
       " 785666               Data Analyst  ...              Sep\n",
       " \n",
       " [62359 rows x 18 columns],\n",
       " 'May':                   job_title_short  ... job_posted_month\n",
       " 45            Senior Data Analyst  ...              May\n",
       " 47           Senior Data Engineer  ...              May\n",
       " 72              Software Engineer  ...              May\n",
       " 80                  Data Engineer  ...              May\n",
       " 110                 Data Engineer  ...              May\n",
       " ...                           ...  ...              ...\n",
       " 785578             Data Scientist  ...              May\n",
       " 785594  Machine Learning Engineer  ...              May\n",
       " 785652          Software Engineer  ...              May\n",
       " 785680          Software Engineer  ...              May\n",
       " 785694              Data Engineer  ...              May\n",
       " \n",
       " [52104 rows x 18 columns]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict_month = {month : df[df[\"job_posted_month\"] == month] for month in month_arr }\n",
    "\n",
    "df_dict_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hoorey!! We created a dictionary of demand don't believe okay lets call the data of Jan and check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_posted_month\n",
       "Jan    91822\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict_month[\"Jan\"][\"job_posted_month\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See when we pull the df store in \"Jan\" key and check for how many time each month(s) is mention in the df,\n",
    "# We get just the Jan entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax for dict Comprehension :\n",
    "# dict = {key:values for key in array/list/...}\n",
    "# Point to be noted : values can be any datatype from str to dataframes; even you can mention the code or condition\n",
    "#                     which create that datatype \n",
    "# IOC, df[df[\"job_posted_month\"] == month(key)] is a condition to create a specific df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luke_py_cor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
